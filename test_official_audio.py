#!/usr/bin/env python3
"""
Test script to verify official LatentSync audio processing implementation
"""

import torch
import numpy as np

def get_sliced_audio_feature(feature_array: torch.Tensor, vid_idx: int, fps: float = 25.0) -> torch.Tensor:
    """
    Step 2: Get small audio slice for specific frame (Official LatentSync feature2chunks)
    This creates tiny embeddings instead of massive ones
    """
    # ðŸ”§ OFFICIAL LATENTSYNC PARAMETERS
    audio_feat_length = [2, 2]  # Official LatentSync audio context window
    embedding_dim = 384  # Whisper Tiny embedding dimension
    
    length = len(feature_array)
    selected_feature = []
    
    # ðŸ”§ OFFICIAL ALGORITHM: Calculate audio indices for this video frame
    center_idx = int(vid_idx * 50 / fps)  # 50Hz is Whisper's internal rate
    left_idx = center_idx - audio_feat_length[0] * 2
    right_idx = center_idx + (audio_feat_length[1] + 1) * 2
    
    # ðŸ”§ OFFICIAL SLICING: Extract small window around current frame
    for idx in range(left_idx, right_idx):
        idx = max(0, idx)  # Clamp to valid range
        idx = min(length - 1, idx)
        
        if idx < len(feature_array):
            x = feature_array[idx]
        else:
            # Pad with zeros if beyond audio length
            x = torch.zeros(embedding_dim, device=feature_array.device, dtype=feature_array.dtype)
        
        selected_feature.append(x)
    
    # ðŸ”§ OFFICIAL FORMAT: Concatenate and reshape
    selected_feature = torch.cat(selected_feature, dim=0)
    selected_feature = selected_feature.reshape(-1, embedding_dim)  # Shape: [10, 384] - TINY!
    
    print(f"ðŸ” Frame {vid_idx}: Audio slice shape {selected_feature.shape} (center_idx: {center_idx})")
    
    return selected_feature

def test_official_audio_processing():
    """Test the official LatentSync audio processing"""
    print("ðŸ§ª Testing Official LatentSync Audio Processing")
    print("=" * 50)
    
    # Create dummy audio features (simulating pre-computed Whisper features)
    audio_features = torch.randn(100, 384)  # 100 time steps, 384 embedding dim
    print(f"ðŸ“Š Dummy audio features shape: {audio_features.shape}")
    
    # Test slicing for different frame indices
    test_frames = [0, 10, 25]
    
    for frame_idx in test_frames:
        print(f"\nðŸŽ¬ Processing frame {frame_idx}:")
        
        # Get audio slice for this frame
        audio_slice = get_sliced_audio_feature(audio_features, frame_idx, fps=25.0)
        
        # Calculate memory usage
        slice_memory_kb = audio_slice.numel() * 4 / 1024  # 4 bytes per float32
        
        print(f"   âœ… Audio slice shape: {audio_slice.shape}")
        print(f"   ðŸ’¾ Memory usage: {slice_memory_kb:.1f} KB")
        
        # Verify it's the correct format for LatentSync
        if audio_slice.dim() == 2 and audio_slice.shape[1] == 384:
            print(f"   âœ… Correct format for LatentSync processing")
        else:
            print(f"   âŒ Incorrect format: expected [seq_len, 384], got {audio_slice.shape}")
    
    # Memory comparison
    print(f"\nðŸ“Š Memory Comparison:")
    print(f"   Old method (raw audio): ~5.7 GB per frame")
    print(f"   New method (sliced features): ~{slice_memory_kb:.1f} KB per frame")
    print(f"   Reduction factor: ~{5.7 * 1024 * 1024 / slice_memory_kb:.0f}x smaller!")
    
    print(f"\nâœ… Official LatentSync audio processing test complete!")

def test_audio_slice_detection():
    """Test that audio slices are properly detected"""
    print("\nðŸ” Testing Audio Slice Detection")
    print("=" * 30)
    
    # Create a proper audio slice
    audio_slice = torch.randn(10, 384)
    print(f"ðŸ“Š Test audio slice shape: {audio_slice.shape}")
    
    # Test detection logic
    if isinstance(audio_slice, torch.Tensor) and audio_slice.dim() == 2 and audio_slice.shape[1] == 384:
        print("âœ… Audio slice correctly detected as pre-computed slice")
    else:
        print("âŒ Audio slice detection failed")
    
    # Test with raw audio
    raw_audio = np.random.randn(16000)  # 1 second of audio at 16kHz
    print(f"ðŸ“Š Test raw audio shape: {raw_audio.shape}")
    
    if isinstance(raw_audio, np.ndarray) and raw_audio.ndim == 1:
        print("âœ… Raw audio correctly detected as raw audio")
    else:
        print("âŒ Raw audio detection failed")

if __name__ == "__main__":
    test_official_audio_processing()
    test_audio_slice_detection() 